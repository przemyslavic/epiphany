---
##########################################################
# This file is autogenerated for environment {{ environment_name }}
# Data file for Epiphany
# Azure specific
##########################################################

###########################
title: Epiphany ({{ azure.image_offer }}) {{ environment_name }}

kind: datafile
version: 0.2.2

# NOTE: Any data values that are empty put "" or the value None will be used in the templates for those attributes.

core:
  # This will apply to a VPN like environment or an air-gapped like environment
  bastian:
    enable: false
    # This host will be set ONLY for environments where a bastian host is supplied to us and NOT part of the cluster build
    host: ''
    # If the bastian host has a different key
    key_path: ''
    user: ''
    # if key_path is ''
    pwd: ''

  build:
    # IMPORTANT - will be appended to release name and output folder and part of the template names
    version: &version 0.2.2
    # Type of build environment
    environment: &env development
    # Name of the given release. Version will be appended
    release: epiphany-dev
    # If repo_root is true then add that as a prefix for the output
    repo_root: true
    platform: azure
    output: '/build/$PLATFORM/infrastructure/epiphany'

  tags: &tags
    - key: environment
      value: *env
    - key: version
      value: *version
    - key: project
      value: epiphany
    - key: location
      value: {{ azure.location }}

  # domain is used to create DNS entries or just add FQDN to hosts.yaml file used in automation
  domain:
    enable: false
    name: example.com
    create_dns: false

  # These will become the role/classification you will use with the automation to group nodes for given tasks
  # Use '_' and not '-' in names
  roles:
    - master
    - worker
    - kafka
    - zookeeper
    - grafana    
    - node_exporter
    - prometheus
    - elasticsearch
    - elasticsearch-curator
    - kibana
    - filebeat
    - jmx-exporter
    - kafka-exporter
    - haproxy_tls_termination
    - haproxy_exporter
    - postgresql
    - rabbitmq
    - deployments
    - reboot
    # These last two must always be present
    - linux
    # - windows
  
  admin_user:
    name: &admin_username operations
    # May want to change to 'key' and create 'key_path' with 'pwd' or 'home'
    key_path: {{ security.keys_directory }}/{{ security.key_file_name }}

  azure:
    tags:
      <<: *tags

    terraform:
      # This version info is what version is being used at the moment. The version of Terraform in the manifest.yaml in the
      # root of the repo is for the initial install and the minum version
      version: 1.6
      service_principal:
        # Three files are required for SPs to work, az_ad_sp.json, env.sh and security.yaml. By default, these are created if the
        # 'create' attribute is true. If false then you will need to supply those two files. This allows you to create
        # a service_principal of your own instead of having one generated.
        # You will also need to override env.sh that contains the 'ARM_...' environment variables required.
        enable: true
        create: {{ azure.create_service_principal }} # If you want to use an existing one then set this to false
      auth: pwd # Valid is 'pwd' and 'cert'. At this time Terraform only support 'pwd' for service principals (sp true)
      # NOTE: Backend is a Terraform resource that stores the *.tfstate files used by Terraform to store state. The default
      # is to store the state file locally but this can cause issues if working in a team environment.
      backend:
        # Only used by Terraform
        # The backend storage account is '<resource_group_name>''backend' (combined name with suffix)
        # The storage container is generated as '<resource_group_name>'-'terraform'
        # NOTE: Known issue with backend tf when having different VM types below when enabled! So, only one VM entry with count set should be used. Set to false for now...
        enable: false
        storage_account:
        storage_container:
        # sleep: 15 # Number of seconds to sleep so that Azure can create the required containers before moving on
        type: blob
        tags: *tags

    # NOTE: May want to create region/AZ sub-folders to support creating a cluster in different regions and AZ for HA...
    resource_group: &resource_group
      name: &name {{ azure.resource_group }}
      location: &location {{ azure.location }}

    # Subscription name or ID
    subscription: {{ azure.subscription_name }}

    # Azure Active Directory
    ad:
      name: *name
      role: Contributor

    standard:
      # One resource group is supported
      resource_group:
        <<: *resource_group
        # exists: false - TO BE REMOVED
        prevent_destory: true
        # IMPORTANT - Do not set lock if you plan on editing anything in the resource group! Leave it set to false until you are ready
        # ReadOnly or CanNotDelete are the only two level options if enabled!
        lock:
          # NOTE: This will cause locks.tf.wait to be generated. You will need a script to rename this to locks.tf and run apply again
          enable: true
          name: epiphany-lock
          level: ReadOnly
          notes: This locks the entire resource group!
        tags: *tags

      # This aids in boot diagnostics if there are issues:
      # https://docs.microsoft.com/en-us/azure/virtual-machines/linux/boot-diagnostics
      debug:
        # WIP
        enable: false
        storage_account:
          name: {{ azure.boot_storage }}
          account:
            tier: Standard
            replication_type: LRS
            # Storage, StorageV2 and BlobStorage are supported types
            kind: StorageV2
        storage_container:
          name: debug

      availability:
        availability_set:
          enable: true
          name: ha-epiphany
          platform_fault_domain_count: 3
          platform_update_domain_count: 5
          managed: true # Best to keep this 'true' in most cases. Mixing availability set managed with vm disk unmanaged is not allowed
          tags: *tags

      security:
        ssh: &ssh
          key:
            # Public portion of the key
            file: {{ security.keys_directory }}/{{ security.public_key_file_name }}
            data:

        vpn:
          # Make SURE all of the data is correct below before enabling 'vpn'. It can also take 30 minutes to an hour to create.
          enable: false
          name: vpn-epiphany
          # Only support RouteBased type of connection currently
          type: RouteBased
          active_active: false
          # There are two types of 'sku' (Basic and Standard). Always use Standard so any client can use.
          sku: Standard
          # Address space that is required by Virtual Network Gateway. This address space must be inside of virtual_network.address_space and do not overlap with other subnets defined  
          gateway_subnet_space: 10.0.3.0/24
          client_configuration:
          # This section is very important!
          # You must specify the address_space that will be allocated to use on the VPN side of the conection that will
          # be able to talk to your cluster.
            address_space:
              - 172.16.0.0/24
            root_certificate:
              # name is the name of the cert that was created for you by a trusted party OR a name you give a self-signed cert
              name: EpiphanyRootCa
              revoked_certificate:
                name: EpiphanyRevoked
                thumbprint: your-revoked-cert-thumbprint
              # public_cert_data is the actual base64 public key from your cert. Put it in 'as is'. The '|' tells yaml to use 'as is'.
              public_cert_data: |
                YOUR-BASE64-CLIENT-AUTH-PUBLIC-KEY

          ip_configuration:
            name: vpn-ip-config
            public_ip:
              output:
                enable: true
                sensitive: false
              name: pip-vpn-epiphany
              address_allocation: dynamic
              idle_timeout_in_minutes: 30

              tags: *tags

            # subnet_id is generated so use terraform variable
            private_ip:
              output:
                enable: true
                sensitive: false
              address_allocation: dynamic
              # address only applies if 'address_allocation' is 'static'
              address: 10.0.2.5

        network_security_group:
          enable: true
          # Note: Could create an array of NSGs and reference them name + '_' + # (i.e., epiphany_nsg_001) maybe at somepoint if needed
          name: security-nsg-epiphany
          tags: *tags

          # Add another NSG rules in order to access resources.
          rules:
            - name: ssh
              description: Allow SSH
              priority: 101
              direction: Inbound
              access: Allow
              protocol: Tcp
              source_port_range: "*"
              destination_port_range:  "22"
              source_address_prefix: "*"
              destination_address_prefix: "*"

        virtual_network:
          name: security-vnet-epiphany
          address_space:
            - 10.0.0.0/8

        subnet:
          name: vnet-subnet-epiphany
          address_prefix: 10.0.0.0/16
          # Service endpoints bypass normal public route to Azure SQL, Storage and CosmosDB services
          service_endpoints:
            - Microsoft.Storage
            - Microsoft.Sql
            - Microsoft.AzureCosmosDB

      # NOTE: Managed vs Unmanaged storage
      # If you want managed storage then by default, 'storage_account' and 'storage_container' options are not required BUT
      # they are still enabled in the 'main.tf.j2' template. This could be set with an enable option.

      storage_managed_disk:
        # WIP
        enable: false
        name: epiphany-mdisk
        storage_account_type: Premium_LRS
        create_option: Empty
        disk_size_gb: 500
        count: 1

      # Once storage account is supported
      # Should use (maybe) a different storage account for different locations. Meaning, if you have two clusters (one in east and one in west) then having a storage account for east and one for west would be good since you want storage near compute.
      # No `-` in storage account name

      # 3-24 Alphanumeric only lower case
      storage_account:
        enable: false
        name: epiphany
        account:
          tier: Standard
          replication_type: LRS
          # Storage, StorageV2 and BlobStorage are supported types
          kind: StorageV2

        tags: *tags

      storage_container:
        enable: false
        # 3-63 Alphanumeric lower case plus '-'
        name: epiphany-osdisks
        access_type: private

      storage_blob:
        enable: false
        name: epiphany-osdisks
        type: page
        # size in bytes in 512 increments
        size: 5120
        count: 2

      storage_image_reference: &storage_image_reference
        # publisher: Canonical
        # offer: UbuntuServer
        # sku: 16.04-LTS
        # Never put latest on anything! Need to always pin the version number but testing we can get away with it
        # version: latest

        publisher: {{ azure.image_publisher }}
        offer: {{ azure.image_offer }}
        sku: {{ azure.image_sku }}
        # Never put latest on anything! Need to always pin the version number but testing we can get away with it
        version: {{ azure.image_version }}

      storage_os_disk: &storage_os_disk
        managed: false
        caching: ReadWrite
        create_option: FromImage
        disk_size_gb: 30
        managed_disk_type: Premium_LRS

      storage_data_disk: &storage_data_disk
        # Determines if a data disk will be added. If also using managed disks then use 'Attach' for create_option instead of 'Empty'
        enable: false
        count: 2
        managed: false
        caching: ReadWrite
        create_option: Empty
        disk_size_gb: 30
        managed_disk_type: Standard_LRS # Can only be Standard_LRS if using non-managed availability_set

      os_profile: &os_profile
        admin_username: operations
        admin_password: YourPwd

      os_profile_linux_config: &os_profile_linux_config
        # NOTE: Must set to true except in early stage development! This will enforce ssh key authentication for now...
        disable_password_authentication: true

      os_profile_windows_config: &os_profile_windows_config
        # NOTE: Must set to true except in early stage development! This will enforce ssh key authentication for now...
        disable_password_authentication: true

      # Testing sets flags that allow builds to inject commands into VMs and other related items
      testing:
        enable: false

      # NOTE: This MUST equal the total number of 'count' metadata from each 'vm' array entry below
      vm_count: 8

      # VM names - 1-15 characters for Windows and 1-64 characters for Linux
      vms:

      vms:
        - name: {{ azure.vm_name_prefix }}-lb 
          size: Standard_DS1_v2
          os_type: linux
          count: 1
          # One host will need to be a bastian host UNLESS the bastian host is provided in another way
          bastian_host: false
          # roles are how you define a grouping of nodes. These values will be used to create an inventory of your cluster
          # Must be a member of the 'role' in core
          roles:
          - linux
          - haproxy_tls_termination
          - haproxy_exporter
          - node_exporter
          - filebeat

          delete_os_disk_on_termination: false
          delete_data_disks_on_termination: false
          # NOTE: This must match the interfaces public_ip options. If one interface has enabled public_ip then this MUST be true else false
          public_ips: true
          depends_on:
            # Put the name of the resource. If a VM then only put the 'name:' value. The count portion will be automatically added
            - '${var.master_depends_on}'
          tags: *tags

          security:
            # Each node will have firewalld (redhat) enabled and allowing only given ports, remember that Epiphany needs port 22 for bootstrapping environments
            firewall:
              enable: false
              ports_open:
                - 22/tcp
                - 443/tcp

          # NOTE: For Kubernetes builds we should *not* use provisioners to bootstrap any data. The point is to build a common
          # infrastructure and then collect IPs etc. that are required for K8s automation to build. The ONLY possible
          # exception is for automated testing in VSTS 
          bootstrap:
            # Can use the global values or override them on a per vm type basis
            ssh: *ssh

            provisioners:
              file:
                enable: false
                # NOTE: Pay close attention to the trailing '/' for 'source'. If you leave '/' off of the end of source then the directory tree will be copied to 'destination'. If you add '/' then the contents of that directory will be copied into the destination directory.
                source: "../../../../core/src/scripts/kubernetes/linux"
                destination: "/home/${var.admin_username}"

              remote_exec:
                enable: false
                # NOTE: Use Terraform vars if you need to embed variables in the commands.
                inline: # Example is below and only here to show
                  - 'chmod +x ${var.file_destination}/linux/make-executable.sh'
                  - '${var.file_destination}/linux/make-executable.sh'
                  - 'echo ${var.admin_password} | sudo -S ${var.file_destination}/linux/prepare-system-kubernetes-redhat.sh'

                testing_inline:
                  - 'echo \"##vso[task.setvariable variable=toPrint]Print Me Please\"'

          interfaces:
            # A VM can have multiple IP addresses and interfaces. In this case we are
            # saying there is one public IP per network interface
            - network_interface:
                # name has vm name appended to it so only put basic type name here
                name: nic
                primary: true
                tags: *tags

                # This only works with certain size VMs
                # Accelerated Networking is supported on most general purpose and compute-optimized instance sizes with 2 or more vCPUs.
                # These supported series are: D/DSv2 and F/Fs. On instances that support hyperthreading, Accelerated Networking is supported
                # on VM instances with 4 or more vCPUs. Supported series are: D/DSv3, E/ESv3, Fsv2, and Ms/Mms.
                # https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli
                enable_accelerated_networking: false

                ip_configuration:
                  name: ip-config
                  # subnet_id is generated so use terraform variable
                  private_ip:
                    output:
                      enable: true
                      sensitive: false
                    address_allocation: Dynamic
                    # address only applies if 'address_allocation' is 'static'
                    address: 10.0.2.5

                public_ip:
                  # If you set to false there must be some host set as a bastian host
                  enable: true
                  output:
                    enable: true
                    sensitive: false
                  name: pip-epiphany
                  address_allocation: static
                  idle_timeout_in_minutes: 30
                  sku: Standard

                  tags: *tags
    
        - name: {{ azure.vm_name_prefix }}-master 
          size: Standard_DS2_v2
          os_type: linux
          count: 1
          # One host will need to be a bastian host UNLESS the bastian host is provided in another way
          bastian_host: false
          # roles are how you define a grouping of nodes. These values will be used to create an inventory of your cluster
          # Must be a member of the 'role' in core
          roles:
            - linux
            - master
            - deployments
            - filebeat
            - node_exporter
            - reboot
          delete_os_disk_on_termination: false
          delete_data_disks_on_termination: false
          # NOTE: This must match the interfaces public_ip options. If one interface has enabled public_ip then this MUST be true else false
          public_ips: true
          depends_on:
            # Put the name of the resource. If a VM then only put the 'name:' value. The count portion will be automatically added
            - '${var.master_depends_on}'
          tags: *tags

          security:
            # Each node will have firewalld (redhat) enabled or not allowing the given ports
            firewall:
              enable: false
              # These ports can be in sync with NSG rules below or not. Meaning, you may have NSG disabled and want each node to block
              # Each node could belong to a different grouping with a need for different ports
              ports_open:
                - 443
                - 22
                - 6443
                - 2379-2380
                - 10250
                - 10251
                - 10252
                - 10255

          # NOTE: For Kubernetes builds we should *not* use provisioners to bootstrap any data. The point is to build a common
          # infrastructure and then collect IPs etc. that are required for K8s automation to build. The ONLY possible
          # exception is for automated testing in VSTS (maybe)
          bootstrap:
            # Can use the global values or override them on a per vm type basis
            ssh: *ssh

            provisioners:
              file:
                enable: false
                # NOTE: Pay close attention to the trailing '/' for 'source'. If you leave '/' off of the end of source then the directory tree will be copied to 'destination'. If you add '/' then the contents of that directory will be copied into the destination directory.
                source: "../../../../core/src/scripts/kubernetes/linux"
                destination: "/home/${var.admin_username}"

              remote_exec:
                enable: false
                # NOTE: Use Terraform vars if you need to embed variables in the commands.
                inline: # Example is below and only here to show
                  - 'chmod +x ${var.file_destination}/linux/make-executable.sh'
                  - '${var.file_destination}/linux/make-executable.sh'
                  - 'echo ${var.admin_password} | sudo -S ${var.file_destination}/linux/prepare-system-kubernetes-redhat.sh'

                testing_inline:
                  - 'echo \"##vso[task.setvariable variable=toPrint]Print Me Please\"'

          interfaces:
            # A VM can have multiple IP addresses and interfaces. In this case we are
            # saying there is one public IP per network interface
            - network_interface:
                # name has vm name appended to it so only put basic type name here
                name: nic
                primary: true
                tags: *tags

                # This only works with certain size VMs
                # Accelerated Networking is supported on most general purpose and compute-optimized instance sizes with 2 or more vCPUs.
                # These supported series are: D/DSv2 and F/Fs. On instances that support hyperthreading, Accelerated Networking is supported
                # on VM instances with 4 or more vCPUs. Supported series are: D/DSv3, E/ESv3, Fsv2, and Ms/Mms.
                # https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli
                enable_accelerated_networking: false

                ip_configuration:
                  name: ip-config
                  # subnet_id is generated so use terraform variable
                  private_ip:
                    output:
                      enable: true
                      sensitive: false
                    address_allocation: dynamic
                    # address only applies if 'address_allocation' is 'static'
                    address: 10.0.2.5

                public_ip:
                  # If you set to false there must be some host set as a bastian host
                  enable: true
                  output:
                    enable: true
                    sensitive: false
                  name: pip-epiphany
                  address_allocation: static
                  idle_timeout_in_minutes: 30
                  sku: Standard
                  tags: *tags

        - name: {{ azure.vm_name_prefix }}-node 
          size: Standard_DS1_v2
          os_type: linux
          count: {{ platform.worker_vms }}
          # One host will need to be a bastian host UNLESS the bastian host is provided in another way
          bastian_host: false
          # roles are how you define a grouping of nodes. These values will be used to create an inventory of your cluster
          # Must be a member of the 'role' in core
          roles:
            - linux
            - worker
            - filebeat
            - node_exporter
            - reboot
          delete_os_disk_on_termination: false
          delete_data_disks_on_termination: false
          # NOTE: This must match the interfaces public_ip options. If one interface has enabled public_ip then this MUST be true else false
          public_ips: true
          depends_on:
            # Put the name of the resource. If a VM then only put the 'name:' value. The count portion will be automatically added
            - '${var.master_depends_on}'
          tags: *tags

          security:
            # Each node will have firewalld (redhat) enabled or not allowing the given ports
            firewall:
              enable: false
              # These ports can be in sync with NSG rules below or not. Meaning, you may have NSG disabled and want each node to block
              # Each node could belong to a different grouping with a need for different ports
              ports_open:
                - 443
                - 22
                - 6443
                - 2379-2380
                - 10250
                - 10251
                - 10252
                - 10255

          # NOTE: For Kubernetes builds we should *not* use provisioners to bootstrap any data. The point is to build a common
          # infrastructure and then collect IPs etc. that are required for K8s automation to build. The ONLY possible
          # exception is for automated testing in VSTS (maybe)
          bootstrap:
            # Can use the global values or override them on a per vm type basis
            ssh: *ssh

            provisioners:
              file:
                enable: false
                # NOTE: Pay close attention to the trailing '/' for 'source'. If you leave '/' off of the end of source then the directory tree will be copied to 'destination'. If you add '/' then the contents of that directory will be copied into the destination directory.
                source: "../../../../core/src/scripts/kubernetes/linux"
                destination: "/home/${var.admin_username}"

              remote_exec:
                enable: false
                # NOTE: Use Terraform vars if you need to embed variables in the commands.
                inline: # Example is below and only here to show
                  - 'chmod +x ${var.file_destination}/linux/make-executable.sh'
                  - '${var.file_destination}/linux/make-executable.sh'
                  - 'echo ${var.admin_password} | sudo -S ${var.file_destination}/linux/prepare-system-kubernetes-redhat.sh'

                testing_inline:
                  - 'echo \"##vso[task.setvariable variable=toPrint]Print Me Please\"'

          interfaces:
            # A VM can have multiple IP addresses and interfaces. In this case we are
            # saying there is one public IP per network interface
            - network_interface:
                # name has vm name appended to it so only put basic type name here
                name: nic
                primary: true
                tags: *tags

                # This only works with certain size VMs
                # Accelerated Networking is supported on most general purpose and compute-optimized instance sizes with 2 or more vCPUs.
                # These supported series are: D/DSv2 and F/Fs. On instances that support hyperthreading, Accelerated Networking is supported
                # on VM instances with 4 or more vCPUs. Supported series are: D/DSv3, E/ESv3, Fsv2, and Ms/Mms.
                # https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli
                enable_accelerated_networking: false

                ip_configuration:
                  name: ip-config
                  # subnet_id is generated so use terraform variable
                  private_ip:
                    output:
                      enable: true
                      sensitive: false
                    address_allocation: dynamic
                    # address only applies if 'address_allocation' is 'static'
                    address: 10.0.2.5

                public_ip:
                  # If you set to false there must be some host set as a bastian host
                  enable: true
                  output:
                    enable: true
                    sensitive: false
                  name: pip-epiphany
                  address_allocation: static
                  idle_timeout_in_minutes: 30
                  sku: Standard
                  tags: *tags

        - name: {{ azure.vm_name_prefix }}-prometheus
          size: Standard_DS1_v2
          os_type: linux
          count: 1
          # One host will need to be a bastian host UNLESS the bastian host is provided in another way
          bastian_host: false
          # roles are how you define a grouping of nodes. These values will be used to create an inventory of your cluster
          # Must be a member of the 'role' in core
          roles:
            - linux
            - prometheus
            - grafana
            - node_exporter
            - filebeat
            - reboot
          delete_os_disk_on_termination: false
          delete_data_disks_on_termination: false
          # NOTE: This must match the interfaces public_ip options. If one interface has enabled public_ip then this MUST be true else false
          public_ips: true
          depends_on:
            # Put the name of the resource. If a VM then only put the 'name:' value. The count portion will be automatically added
            - '${var.master_depends_on}'
          tags: *tags

          security:
            # Each node will have firewalld (redhat) enabled or not allowing the given ports
            firewall:
              enable: false
              # These ports can be in sync with NSG rules below or not. Meaning, you may have NSG disabled and want each node to block
              # Each node could belong to a different grouping with a need for different ports
              ports_open:
                - 443
                - 22
                - 6443
                - 2379-2380
                - 10250
                - 10251
                - 10252
                - 10255

          # NOTE: For Kubernetes builds we should *not* use provisioners to bootstrap any data. The point is to build a common
          # infrastructure and then collect IPs etc. that are required for K8s automation to build. The ONLY possible
          # exception is for automated testing in VSTS (maybe)
          bootstrap:
            # Can use the global values or override them on a per vm type basis
            ssh: *ssh

            provisioners:
              file:
                enable: false
                # NOTE: Pay close attention to the trailing '/' for 'source'. If you leave '/' off of the end of source then the directory tree will be copied to 'destination'. If you add '/' then the contents of that directory will be copied into the destination directory.
                source: "../../../../core/src/scripts/kubernetes/linux"
                destination: "/home/${var.admin_username}"

              remote_exec:
                enable: false
                # NOTE: Use Terraform vars if you need to embed variables in the commands.
                inline: # Example is below and only here to show
                  - 'chmod +x ${var.file_destination}/linux/make-executable.sh'
                  - '${var.file_destination}/linux/make-executable.sh'
                  - 'echo ${var.admin_password} | sudo -S ${var.file_destination}/linux/prepare-system-kubernetes-redhat.sh'

                testing_inline:
                  - 'echo \"##vso[task.setvariable variable=toPrint]Print Me Please\"'

          interfaces:
            # A VM can have multiple IP addresses and interfaces. In this case we are
            # saying there is one public IP per network interface
            - network_interface:
                # name has vm name appended to it so only put basic type name here
                name: nic
                primary: true
                tags: *tags

                # This only works with certain size VMs
                # Accelerated Networking is supported on most general purpose and compute-optimized instance sizes with 2 or more vCPUs.
                # These supported series are: D/DSv2 and F/Fs. On instances that support hyperthreading, Accelerated Networking is supported
                # on VM instances with 4 or more vCPUs. Supported series are: D/DSv3, E/ESv3, Fsv2, and Ms/Mms.
                # https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli
                enable_accelerated_networking: false

                ip_configuration:
                  name: ip-config
                  # subnet_id is generated so use terraform variable
                  private_ip:
                    output:
                      enable: true
                      sensitive: false
                    address_allocation: dynamic
                    # address only applies if 'address_allocation' is 'static'
                    address: 10.0.2.5

                public_ip:
                  # If you set to false there must be some host set as a bastian host
                  enable: true
                  output:
                    enable: true
                    sensitive: false
                  name: pip-epiphany
                  address_allocation: static
                  idle_timeout_in_minutes: 30
                  sku: Standard
                  tags: *tags

{% if platform.kafka_vms is defined and platform.kafka_vms > 0 %}
        - name: {{ azure.vm_name_prefix }}-kafka
          size: Standard_DS2_v2
          os_type: linux
          count: {{ platform.kafka_vms }}
          # One host will need to be a bastian host UNLESS the bastian host is provided in another way
          bastian_host: false
          # roles are how you define a grouping of nodes. These values will be used to create an inventory of your cluster
          # Must be a member of the 'role' in core
          roles:
            - linux
            - jmx-exporter
            - zookeeper
            - kafka
            - node_exporter
            - filebeat
            - kafka-exporter
            - reboot
          delete_os_disk_on_termination: false
          delete_data_disks_on_termination: false
          # NOTE: This must match the interfaces public_ip options. If one interface has enabled public_ip then this MUST be true else false
          public_ips: true
          depends_on:
            # Put the name of the resource. If a VM then only put the 'name:' value. The count portion will be automatically added
            - '${var.master_depends_on}'
          tags: *tags

          security:
            # Each node will have firewalld (redhat) enabled or not allowing the given ports
            firewall:
              enable: false
              # These ports can be in sync with NSG rules below or not. Meaning, you may have NSG disabled and want each node to block
              # Each node could belong to a different grouping with a need for different ports
              ports_open:
                - 443
                - 22
                - 6443
                - 2379-2380
                - 10250
                - 10251
                - 10252
                - 10255

          # NOTE: For Kubernetes builds we should *not* use provisioners to bootstrap any data. The point is to build a common
          # infrastructure and then collect IPs etc. that are required for K8s automation to build. The ONLY possible
          # exception is for automated testing in VSTS (maybe)
          bootstrap:
            # Can use the global values or override them on a per vm type basis
            ssh: *ssh

            provisioners:
              file:
                enable: false
                # NOTE: Pay close attention to the trailing '/' for 'source'. If you leave '/' off of the end of source then the directory tree will be copied to 'destination'. If you add '/' then the contents of that directory will be copied into the destination directory.
                source: "../../../../core/src/scripts/kubernetes/linux"
                destination: "/home/${var.admin_username}"

              remote_exec:
                enable: false
                # NOTE: Use Terraform vars if you need to embed variables in the commands.
                inline: # Example is below and only here to show
                  - 'chmod +x ${var.file_destination}/linux/make-executable.sh'
                  - '${var.file_destination}/linux/make-executable.sh'
                  - 'echo ${var.admin_password} | sudo -S ${var.file_destination}/linux/prepare-system-kubernetes-redhat.sh'

                testing_inline:
                  - 'echo \"##vso[task.setvariable variable=toPrint]Print Me Please\"'

          interfaces:
            # A VM can have multiple IP addresses and interfaces. In this case we are
            # saying there is one public IP per network interface
            - network_interface:
                # name has vm name appended to it so only put basic type name here
                name: nic
                primary: true
                tags: *tags

                # This only works with certain size VMs
                # Accelerated Networking is supported on most general purpose and compute-optimized instance sizes with 2 or more vCPUs.
                # These supported series are: D/DSv2 and F/Fs. On instances that support hyperthreading, Accelerated Networking is supported
                # on VM instances with 4 or more vCPUs. Supported series are: D/DSv3, E/ESv3, Fsv2, and Ms/Mms.
                # https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli
                enable_accelerated_networking: false

                ip_configuration:
                  name: ip-config
                  # subnet_id is generated so use terraform variable
                  private_ip:
                    output:
                      enable: true
                      sensitive: false
                    address_allocation: dynamic
                    # address only applies if 'address_allocation' is 'static'
                    address: 10.0.2.5

                public_ip:
                  # If you set to false there must be some host set as a bastian host
                  enable: true
                  output:
                    enable: true
                    sensitive: false
                  name: pip-epiphany
                  address_allocation: static
                  idle_timeout_in_minutes: 30
                  sku: Standard
                  tags: *tags
{% endif %}

        - name: {{ azure.vm_name_prefix }}-elk
          size: Standard_DS1_v2
          os_type: linux
          count: 1
          # One host will need to be a bastian host UNLESS the bastian host is provided in another way
          bastian_host: false
          # roles are how you define a grouping of nodes. These values will be used to create an inventory of your cluster
          # Must be a member of the 'role' in core
          roles:
            - linux
            - node_exporter
            - elasticsearch
            - elasticsearch-curator
            - kibana
            - filebeat

          delete_os_disk_on_termination: false
          delete_data_disks_on_termination: false
          # NOTE: This must match the interfaces public_ip options. If one interface has enabled public_ip then this MUST be true else false
          public_ips: true
          depends_on:
            # Put the name of the resource. If a VM then only put the 'name:' value. The count portion will be automatically added
            - '${var.master_depends_on}'
          tags: *tags

          security:
            # Each node will have firewalld (redhat) enabled or not allowing the given ports
            firewall:
              enable: false
              # These ports can be in sync with NSG rules below or not. Meaning, you may have NSG disabled and want each node to block
              # Each node could belong to a different grouping with a need for different ports
              ports_open:
                - 443
                - 22
                - 6443
                - 2379-2380
                - 10250
                - 10251
                - 10252
                - 10255

          # NOTE: For Kubernetes builds we should *not* use provisioners to bootstrap any data. The point is to build a common
          # infrastructure and then collect IPs etc. that are required for K8s automation to build. The ONLY possible
          # exception is for automated testing in VSTS (maybe)
          bootstrap:
            # Can use the global values or override them on a per vm type basis
            ssh: *ssh

            provisioners:
              file:
                enable: false
                # NOTE: Pay close attention to the trailing '/' for 'source'. If you leave '/' off of the end of source then the directory tree will be copied to 'destination'. If you add '/' then the contents of that directory will be copied into the destination directory.
                source: "../../../../core/src/scripts/kubernetes/linux"
                destination: "/home/${var.admin_username}"

              remote_exec:
                enable: false
                # NOTE: Use Terraform vars if you need to embed variables in the commands.
                inline: # Example is below and only here to show
                  - 'chmod +x ${var.file_destination}/linux/make-executable.sh'
                  - '${var.file_destination}/linux/make-executable.sh'
                  - 'echo ${var.admin_password} | sudo -S ${var.file_destination}/linux/prepare-system-kubernetes-redhat.sh'

                testing_inline:
                  - 'echo \"##vso[task.setvariable variable=toPrint]Print Me Please\"'

          interfaces:
            # A VM can have multiple IP addresses and interfaces. In this case we are
            # saying there is one public IP per network interface
            - network_interface:
                # name has vm name appended to it so only put basic type name here
                name: nic
                primary: true
                tags: *tags

                # This only works with certain size VMs
                # Accelerated Networking is supported on most general purpose and compute-optimized instance sizes with 2 or more vCPUs.
                # These supported series are: D/DSv2 and F/Fs. On instances that support hyperthreading, Accelerated Networking is supported
                # on VM instances with 4 or more vCPUs. Supported series are: D/DSv3, E/ESv3, Fsv2, and Ms/Mms.
                # https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli
                enable_accelerated_networking: false

                ip_configuration:
                  name: ip-config
                  # subnet_id is generated so use terraform variable
                  private_ip:
                    output:
                      enable: true
                      sensitive: false
                    address_allocation: dynamic
                    # address only applies if 'address_allocation' is 'static'
                    address: 10.0.2.5

                public_ip:
                  # If you set to false there must be some host set as a bastian host
                  enable: true
                  output:
                    enable: true
                    sensitive: false
                  name: pip-epiphany
                  address_allocation: static
                  idle_timeout_in_minutes: 30
                  sku: Standard
                  tags: *tags

{% if platform.postgresql_vms is defined and platform.postgresql_vms > 0 %}
        - name: {{ azure.vm_name_prefix }}-postgresql
          size: Standard_DS1_v2
          os_type: linux
          count: {{ platform.postgresql_vms }}
          # One host will need to be a bastian host UNLESS the bastian host is provided in another way
          bastian_host: false
          # roles are how you define a grouping of nodes. These values will be used to create an inventory of your cluster
          # Must be a member of the 'role' in core
          roles:
          - node_exporter
          - filebeat
          - postgresql
          - linux

          delete_os_disk_on_termination: false
          delete_data_disks_on_termination: false
          # NOTE: This must match the interfaces public_ip options. If one interface has enabled public_ip then this MUST be true else false
          public_ips: true
          depends_on:
            # Put the name of the resource. If a VM then only put the 'name:' value. The count portion will be automatically added
            - '${var.master_depends_on}'
          tags: *tags

          security:
            # Each node will have firewalld (redhat) enabled and allowing only given ports, remember that Epiphany needs port 22 for bootstrapping environments
            firewall:
              enable: false
              ports_open:
                - 22/tcp
                - 443/tcp

          # NOTE: For Kubernetes builds we should *not* use provisioners to bootstrap any data. The point is to build a common
          # infrastructure and then collect IPs etc. that are required for K8s automation to build. The ONLY possible
          # exception is for automated testing in VSTS 
          bootstrap:
            # Can use the global values or override them on a per vm type basis
            ssh: *ssh

            provisioners:
              file:
                enable: false
                # NOTE: Pay close attention to the trailing '/' for 'source'. If you leave '/' off of the end of source then the directory tree will be copied to 'destination'. If you add '/' then the contents of that directory will be copied into the destination directory.
                source: "../../../../core/src/scripts/kubernetes/linux"
                destination: "/home/${var.admin_username}"

              remote_exec:
                enable: false
                # NOTE: Use Terraform vars if you need to embed variables in the commands.
                inline: # Example is below and only here to show
                  - 'chmod +x ${var.file_destination}/linux/make-executable.sh'
                  - '${var.file_destination}/linux/make-executable.sh'
                  - 'echo ${var.admin_password} | sudo -S ${var.file_destination}/linux/prepare-system-kubernetes-redhat.sh'

                testing_inline:
                  - 'echo \"##vso[task.setvariable variable=toPrint]Print Me Please\"'

          interfaces:
            # A VM can have multiple IP addresses and interfaces. In this case we are
            # saying there is one public IP per network interface
            - network_interface:
                # name has vm name appended to it so only put basic type name here
                name: nic
                primary: true
                tags: *tags

                # This only works with certain size VMs
                # Accelerated Networking is supported on most general purpose and compute-optimized instance sizes with 2 or more vCPUs.
                # These supported series are: D/DSv2 and F/Fs. On instances that support hyperthreading, Accelerated Networking is supported
                # on VM instances with 4 or more vCPUs. Supported series are: D/DSv3, E/ESv3, Fsv2, and Ms/Mms.
                # https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli
                enable_accelerated_networking: false

                ip_configuration:
                  name: ip-config
                  # subnet_id is generated so use terraform variable
                  private_ip:
                    output:
                      enable: true
                      sensitive: false
                    address_allocation: Dynamic
                    # address only applies if 'address_allocation' is 'static'
                    address: 10.0.2.5

                public_ip:
                  # If you set to false there must be some host set as a bastian host
                  enable: true
                  output:
                    enable: true
                    sensitive: false
                  name: pip-epiphany
                  address_allocation: static
                  idle_timeout_in_minutes: 30
                  sku: Standard
                  tags: *tags
{% endif %}

{% if platform.rabbitmq_vms is defined and platform.rabbitmq_vms > 0 %}
        - name: {{ azure.vm_name_prefix }}-rabbitmq
          size: Standard_DS1_v2
          os_type: linux
          count: {{ platform.rabbitmq_vms }}
          # One host will need to be a bastian host UNLESS the bastian host is provided in another way
          bastian_host: false
          # roles are how you define a grouping of nodes. These values will be used to create an inventory of your cluster
          # Must be a member of the 'role' in core
          roles:
          - node_exporter
          - filebeat
          - rabbitmq
          - linux

          delete_os_disk_on_termination: false
          delete_data_disks_on_termination: false
          # NOTE: This must match the interfaces public_ip options. If one interface has enabled public_ip then this MUST be true else false
          public_ips: true
          depends_on:
            # Put the name of the resource. If a VM then only put the 'name:' value. The count portion will be automatically added
            - '${var.master_depends_on}'
          tags: *tags

          security:
            # Each node will have firewalld (redhat) enabled and allowing only given ports, remember that Epiphany needs port 22 for bootstrapping environments
            firewall:
              enable: false
              ports_open:
                - 22/tcp
                - 443/tcp

          # NOTE: For Kubernetes builds we should *not* use provisioners to bootstrap any data. The point is to build a common
          # infrastructure and then collect IPs etc. that are required for K8s automation to build. The ONLY possible
          # exception is for automated testing in VSTS 
          bootstrap:
            # Can use the global values or override them on a per vm type basis
            ssh: *ssh

            provisioners:
              file:
                enable: false
                # NOTE: Pay close attention to the trailing '/' for 'source'. If you leave '/' off of the end of source then the directory tree will be copied to 'destination'. If you add '/' then the contents of that directory will be copied into the destination directory.
                source: "../../../../core/src/scripts/kubernetes/linux"
                destination: "/home/${var.admin_username}"

              remote_exec:
                enable: false
                # NOTE: Use Terraform vars if you need to embed variables in the commands.
                inline: # Example is below and only here to show
                  - 'chmod +x ${var.file_destination}/linux/make-executable.sh'
                  - '${var.file_destination}/linux/make-executable.sh'
                  - 'echo ${var.admin_password} | sudo -S ${var.file_destination}/linux/prepare-system-kubernetes-redhat.sh'

                testing_inline:
                  - 'echo \"##vso[task.setvariable variable=toPrint]Print Me Please\"'

          interfaces:
            # A VM can have multiple IP addresses and interfaces. In this case we are
            # saying there is one public IP per network interface
            - network_interface:
                # name has vm name appended to it so only put basic type name here
                name: nic
                primary: true
                tags: *tags

                # This only works with certain size VMs
                # Accelerated Networking is supported on most general purpose and compute-optimized instance sizes with 2 or more vCPUs.
                # These supported series are: D/DSv2 and F/Fs. On instances that support hyperthreading, Accelerated Networking is supported
                # on VM instances with 4 or more vCPUs. Supported series are: D/DSv3, E/ESv3, Fsv2, and Ms/Mms.
                # https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli
                enable_accelerated_networking: false

                ip_configuration:
                  name: ip-config
                  # subnet_id is generated so use terraform variable
                  private_ip:
                    output:
                      enable: true
                      sensitive: false
                    address_allocation: Dynamic
                    # address only applies if 'address_allocation' is 'static'
                    address: 10.0.2.5

                public_ip:
                  # If you set to false there must be some host set as a bastian host
                  enable: true
                  output:
                    enable: true
                    sensitive: false
                  name: pip-epiphany
                  address_allocation: static
                  idle_timeout_in_minutes: 30
                  sku: Standard
                  tags: *tags
{% endif %}

  kubernetes:
    version: 1.13.1
    # image_registry_secrets:
    # - name: regcred
    #   server_url: your-registry-url 
    #   username: your-registry-username
    #   password: your-registry-password
    #   email: your-registry-email
    #   namespace: your-secret-namespace
    storage:
      enable: true
      #valid chocies:
        #azure-file
        #WIP
      type: azure-file
      tags: *tags
      quota: 50
    deployments:
      - name: rabbitmq 
        image_path: rabbitmq:3.7.10
        #image_pull_secret_name: regcred # optional
        service:
          name: rabbitmq-cluster
          port: 30672
          management_port: 31672
          replicas: 2
          namespace: queue
        rabbitmq:
          #amqp_port: 5672 #optional - default 5672  
          plugins: # optional list of RabbitMQ plugins
            - rabbitmq_management
            - rabbitmq_management_agent
          policies: # optional list of RabbitMQ policies
            - name: ha-policy2
              pattern: ".*"
              definitions:
                ha-mode: all
          custom_configurations: #optional list of RabbitMQ configurations (new format -> https://www.rabbitmq.com/configure.html)
            - name: vm_memory_high_watermark.relative
              value: 0.5
          cluster:
            #is_clustered: true #redundant in in-Kubernetes installation, it will always be clustered
            #cookie: "cookieSetFromDataYaml" #optional - default value will be random generated string
      - name: auth-service # this service require postgresql to be installed in cluster
        image_path: jboss/keycloak:4.8.3.Final
        #image_pull_secret_name: regcred
        service:
          name: as-testauthdb
          port: 30104
          replicas: 2
          namespace: namespace-for-auth
          admin_user: auth-service-username
          admin_password: auth-service-password
        database: 
          name: "auth-database-name"    
          #port: "5432" # leave it when default
          user: "auth-db-user"
          password: "auth-db-password"

  haproxy:
    stats:
      enable: true
      user: operations
      password: your-haproxy-stats-pwd
    frontend:
      - name: https_front
        port: 443
        https: yes
        backend:
        - http_back1
    backend:
      - name: http_back1
        server_groups:
        - worker
        #servers:
        # Definition for server to that hosts the application.
        #- name: "node1"
        #  address: "epiphany-vm1.domain.com"
        port: 30104

  monitoring:
    alerts:
      enable: True # required value
      handlers:
        mail:
          enable: False # required value
          smtp_from: "alert@test.com"
          smtp_host: "smtp-url:smtp-port"
          smtp_auth_username: "your-smtp-user@domain.com"
          smtp_auth_password: "your-smtp-password"
          smtp_require_tls: True
          recipients: 
          - recipient1@domain.com
          - recipient2@domain.com
        slack:
          enable: False # required value
          api_url: url-to-slack-workspace-api.slack.com
        pagerduty:
          enable: False # required value
          service_key: your-service-key 
      rules:
      - name: "UpDown"
        expression: up == 0
        duration: 1m #1s, 1m, 1h, 1d, 1w, ...
        severity: critical
        message: "Node is down." 
      - name: "DiskSpace"
        expression: ((node_filesystem_avail_bytes* 100) / node_filesystem_size_bytes) < 20 # 100 - 80
        duration: 1m #1s, 1m, 1h, 1d, 1w, ...
        severity: critical
        message: "Disk usage is above 80%" 
      - name: "DiskSpacePrediction"
        expression: predict_linear(node_filesystem_free_bytes{job="node"}[1h], 48 * 3600) < 0
        duration: 1m #1s, 1m, 1h, 1d, 1w, ...
        severity: warning
        message: "Disk will run out of space in less than 48h" 
      - name: "MemoryUsage"
        expression: (sum by (instance) (node_memory_MemTotal_bytes) - sum by (instance)(node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) ) / sum by (instance)(node_memory_MemTotal_bytes) * 100 > 80
        duration: 15m #1s, 1m, 1h, 1d, 1w, ...
        severity: warning
        message: "Server memory has been used in more than 80% during last 15 minutes." 
      - name: "CpuLoad"
        expression: 100 - (avg by (instance) (irate(node_cpu_seconds_total{job="node",mode="idle"}[5m])) * 100) > 80
        duration: 15m #1s, 1m, 1h, 1d, 1w, ...
        severity: critical
        message: "CPU utilization has exceeded 80% over last 15 minutes." 
      - name: "KafkaConsumerLag"
        expression: sum by(consumergroup) (kafka_consumergroup_lag) > 1000
        duration: 15m #1s, 1m, 1h, 1d, 1w, ...
        severity: critical
        message: "Kafka consumers are lagging more than 1000 messages over last 15 minutes." 

  rabbitmq:
    amqp_port: 5672 #optional - default 5672  
    plugins: # optional list of RabbitMQ plugins
      - rabbitmq_management
      - rabbitmq_management_agent
    policies: # optional list of RabbitMQ policies
      - name: ha-policy2
        pattern: ".*"
        definitions:
          ha-mode: all
    custom_configurations: #optional list of RabbitMQ configurations (new format -> https://www.rabbitmq.com/configure.html)
      - name: vm_memory_high_watermark.relative
        value: 0.6
    cluster:
      is_clustered: true #optional - default false
      cookie: "cookieSetFromDataYaml" #optional - default value will be random generated string
      
  postgresql:
    replication:
      enable: yes
      user: postgresql-replica-user
      password: postgresql-replica-pass
      max_wal_senders: 10 # (optional) - default value 5
      wal_keep_segments: 34 # (optional) - default value 32